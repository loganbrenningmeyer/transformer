# ====================
# Run Configuration
# ====================
run: 
  name: samples_test
  runs_dir: ./runs/lm

# ====================
# Training Parameters
# ====================
train:
  steps: 100
  lr: 0.0001

# ====================
# Model Configuration
# ====================
model:
  d_model: 512
  num_heads: 4
  num_encoder_layers: 2
  num_decoder_layers: 2
  dropout: 0.1

# ====================
# Dataset Configuration
# ====================
data:
  dataset: tiny_shakespeare
  batch_size: 8
  vocab_size: 300
  block_size: 256

# ====================
# Sampling Parameters
# ====================
sampling:
  prompt: "ROMEO:\n"
  max_tokens: 256
  multinomial: true
  temperature: 1.0

# ====================
# Logging Parameters
# ====================
logging:

  wandb:
    enable: false
    save_ckpt: 0

  loss_interval: 1
  ckpt_interval: 50000
  sample_interval: 50