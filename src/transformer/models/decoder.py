import torch
import torch.nn as nn

from transformer.models.attention import SelfAttention, CrossAttention


class Decoder(nn.Module):
    """
    
    
    Args:
    
    
    Returns:
    
    """
    def __init__(self):
        super().__init__()
        pass

    def forward(self, tgt: torch.Tensor):
        pass


